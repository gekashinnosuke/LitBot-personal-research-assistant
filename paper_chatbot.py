# ============================================
# è«–æ–‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆStreamlit + Embeddingï¼‰
# ============================================

import streamlit as st
import openai
import numpy as np
import os
import streamlit as st

from PyPDF2 import PdfReader

# ===============================
# è¨­å®š
# ===============================
openai.api_key = os.environ["OPENAI_API_KEY"]

EMBED_MODEL = "text-embedding-3-large"
CHAT_MODEL = "gpt-5.1"


# ===============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ===============================
def split_text(text, chunk_size=200):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]


def get_embedding(text):
    res = openai.embeddings.create(
        model=EMBED_MODEL,
        input=text
    )
    return res.data[0].embedding


def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="è«–æ–‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ“š LitBot-è«–æ–‡ã®ãŠä¾›ã€æ•´ç†ã¨è¦ç´„ã‚’ã‚µãƒãƒ¼ãƒˆ")

st.markdown("""
PDFã‚’ç™»éŒ²ã—ã¦ã€è³ªå•ã—ã¦ãã ã•ã„ã€‚  
""")

# ===============================
# PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ===============================
uploaded_files = st.file_uploader(
    "è«–æ–‡PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
    type="pdf",
    accept_multiple_files=True
)

if uploaded_files and "embeddings" not in st.session_state:
    with st.spinner("è«–æ–‡ã‚’èª­ã¿è¾¼ã¿ãƒ»Embeddingä¸­..."):
        all_chunks = []
        all_embeddings = []

        for pdf in uploaded_files:
            reader = PdfReader(pdf)
            text = ""

            for page in reader.pages:
                t = page.extract_text()
                if t:
                    text += t + "\n"

            chunks = split_text(text)

            for chunk in chunks:
             if len(chunk.strip()) < 20:
              continue
             all_chunks.append({
                 "filename": pdf.name,
                 "text": chunk
            })
             all_embeddings.append(get_embedding(chunk))


        st.session_state["chunks"] = all_chunks
        st.session_state["embeddings"] = all_embeddings

    st.success("è«–æ–‡ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# ===============================
# ãƒãƒ£ãƒƒãƒˆ
# ===============================
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

question = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if question and "embeddings" in st.session_state:
    st.session_state["messages"].append({"role": "user", "content": question})
    st.chat_message("user").write(question)

    with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
        q_emb = get_embedding(question)

        scores = [
            cosine_similarity(q_emb, emb)
            for emb in st.session_state["embeddings"]
        ]

        top_idx = np.argsort(scores)[-5:]

        context = ""
        for i in top_idx:
            chunk = st.session_state["chunks"][i]
            context += f"[è«–æ–‡: {chunk['filename']}]\n{chunk['text']}\n\n"

        prompt = f"""
ä»¥ä¸‹ã¯è¤‡æ•°è«–æ–‡ã‹ã‚‰æŠ½å‡ºã—ãŸé–¢é€£éƒ¨åˆ†ã§ã™ã€‚
ã“ã‚Œã‚’å‚è€ƒã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚ç´°ã‹ãªæ•°å­—ã°ã‹ã‚Šãªãªã‚‰ãšã«ã€ä»£è¡¨ä¾‹ã‚’ç¤ºã™ã¨ãã ã‘æ•°å­—ã‚’ä½¿ã†ã€‚ç›¸æ‰‹ãŒãã®åˆ†é‡ã®ç´ äººã ã¨æ€ã£ã¦ã€‚é•·ã™ããšã€å¹³å‡400å­—ãã‚‰ã„ã€‚
æœ¬è³ªã‚’ä¼ãˆã‚‹ã€‚æœ€å¾Œã«ã€è³ªå•ã•ã‚ŒãŸå†…å®¹ã«é–¢é€£ã®ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã€Œã“ã‚Œã«ã¤ã„ã¦ã‚‚çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿã€ã¨èãã€‚ã“ã‚Œã¨ãªã‚‰ã¹ã¦ã€Œã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿã€ã¨èãã€‚ãã‚Œã«ã‚¤ã‚¨ã‚¹ã¨ç­”ãˆãŸã‚‰ã€å…·ä½“çš„ãªæ•°å­—ã‚„è©³ç´°ã‚’ç”¨ã„ã¦èª¬æ˜ã™ã‚‹ã€‚ã“ã®äºŒã¤ã®è³ªå•ã®éƒ¨åˆ†ã¯ã€æ–‡å­—æ•°ã«å«ã¾ãªã„ã€‚

{context}

è³ªå•:
{question}
"""

        response = openai.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        answer = response.choices[0].message.content.strip()

    st.session_state["messages"].append(
        {"role": "assistant", "content": answer}
    )
    st.chat_message("assistant").write(answer)

elif question:
    st.warning("å…ˆã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
