# ============================================
# è«–æ–‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆStreamlit + Embeddingï¼‰
# ============================================

import streamlit as st
import openai
import numpy as np
import os
import streamlit as st

APP_PASSWORD = os.environ["litbot1222"]

if "authenticated" not in st.session_state:
    st.session_state["authenticated"] = False

if not st.session_state["authenticated"]:
    st.title("ğŸ”’ LitBot ãƒ­ã‚°ã‚¤ãƒ³")

    password = st.text_input(
        "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        type="password"
    )

    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if password == APP_PASSWORD:
            st.session_state["authenticated"] = True
            st.experimental_rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")

    st.stop()  # â† ã“ã“è¶…é‡è¦

from PyPDF2 import PdfReader

# ===============================
# è¨­å®š
# ===============================
openai.api_key = os.environ["OPENAI_API_KEY"]

EMBED_MODEL = "text-embedding-3-large"
CHAT_MODEL = "gpt-5.1"


# ===============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ===============================
def split_text(text, chunk_size=500):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]


def get_embedding(text):
    res = openai.embeddings.create(
        model=EMBED_MODEL,
        input=text
    )
    return res.data[0].embedding


def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="è«–æ–‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ“š è«–æ–‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

st.markdown("""
PDFè«–æ–‡ã‚’ç™»éŒ²ã—ã¦ã€ChatGPTã®ã‚ˆã†ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚  
è£ã§ã¯ **Embeddingæ¤œç´¢** ãŒå‹•ã„ã¦ã„ã¾ã™ã€‚
""")

# ===============================
# PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ===============================
uploaded_files = st.file_uploader(
    "è«–æ–‡PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
    type="pdf",
    accept_multiple_files=True
)

if uploaded_files and "embeddings" not in st.session_state:
    with st.spinner("è«–æ–‡ã‚’èª­ã¿è¾¼ã¿ãƒ»Embeddingä¸­..."):
        all_chunks = []
        all_embeddings = []

        for pdf in uploaded_files:
            reader = PdfReader(pdf)
            text = ""

            for page in reader.pages:
                t = page.extract_text()
                if t:
                    text += t + "\n"

            chunks = split_text(text)

            for chunk in chunks:
                all_chunks.append({
                    "filename": pdf.name,
                    "text": chunk
                })
                all_embeddings.append(get_embedding(chunk))

        st.session_state["chunks"] = all_chunks
        st.session_state["embeddings"] = all_embeddings

    st.success("è«–æ–‡ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# ===============================
# ãƒãƒ£ãƒƒãƒˆ
# ===============================
if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

question = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if question and "embeddings" in st.session_state:
    st.session_state["messages"].append({"role": "user", "content": question})
    st.chat_message("user").write(question)

    with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
        q_emb = get_embedding(question)

        scores = [
            cosine_similarity(q_emb, emb)
            for emb in st.session_state["embeddings"]
        ]

        top_idx = np.argsort(scores)[-5:]

        context = ""
        for i in top_idx:
            chunk = st.session_state["chunks"][i]
            context += f"[è«–æ–‡: {chunk['filename']}]\n{chunk['text']}\n\n"

        prompt = f"""
ä»¥ä¸‹ã¯è¤‡æ•°è«–æ–‡ã‹ã‚‰æŠ½å‡ºã—ãŸé–¢é€£éƒ¨åˆ†ã§ã™ã€‚
ã“ã‚Œã‚’å‚è€ƒã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

{context}

è³ªå•:
{question}
"""

        response = openai.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        answer = response.choices[0].message.content.strip()

    st.session_state["messages"].append(
        {"role": "assistant", "content": answer}
    )
    st.chat_message("assistant").write(answer)

elif question:
    st.warning("å…ˆã«PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
